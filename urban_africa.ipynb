{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban Africa\n",
    "\n",
    "This notebook uses the Africapolis 2015 data to append a csv dataset containing longitudes and latitudes with a new attribute specifying whether each long/lat pair lies in an urban area or not. This task is completed by checking whether each point lies inside any of the polygons defining the borders of African cities, given by the Africapolis dataset: https://africapolis.org/data This dataset is automatically downloaded if it is not already present in the specified directory.\n",
    "\n",
    "Depending on the size of the dataset and your processing power, this can take some time. If you are using Google colab, it may not be worth utilising the multiprocessing option, as by default you will only have 2 CPUs. However, if the dataset is very large, this may still be better than just one CPU. Through experimenting with my own laptop (12 cores) it seems that using multiprocessing with 6 processors reduces runtime by a lot for a relatively small dataset (~5000 entries) from 2m 48s to 1m 30s, so for large datasets it is likely worth using. Using a few more or less makes little difference, so I have made the default half of the available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oD_8IZ3HniLY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b2e216fb3265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## If using Google Colab, run this block to access data in your Google Drive.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "## If using Google Colab, run this block to access data in your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E4sT2ALoHHo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\ewand\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from geopandas) (1.0.1)\n",
      "Requirement already satisfied: pyproj in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: shapely in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from geopandas) (1.6.4.post1)\n",
      "Requirement already satisfied: fiona in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from geopandas) (1.8.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: attrs>=17 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (19.3.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (7.0)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (0.5.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: six>=1.7 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (1.14.0)\n",
      "Requirement already satisfied: munch in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: pdl in c:\\users\\ewand\\anaconda3\\lib\\site-packages (0.8.18)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from pdl) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->pdl) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->pdl) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->pdl) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ewand\\anaconda3\\lib\\site-packages (from requests>=2.18.4->pdl) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "## If using Google Colab, these packages will need to be installed\n",
    "!pip install geopandas\n",
    "!pip install pdl\n",
    "## If not, then any packages you have not installed will need to be installed, so include them as needed\n",
    "#!pip install pandas\n",
    "#!pip install tqdm\n",
    "#!pip install dask\n",
    "#!pip install multiprocessing\n",
    "#!pip install numpy\n",
    "#!pip install os\n",
    "#!pip install sys\n",
    "#!pip install time\n",
    "#!pip install threading\n",
    "#!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjxdoT6mnwr8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from pdl import pdl\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import jellyfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the application\n",
    "\n",
    "This block will begin running the application. You will be prompted to provide file paths and other necessary information. The data will then be processed, and saved to the given file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "CERDP3vboVCf",
    "outputId": "5a33fcc7-c621-40b2-862f-118a6b708893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the directory containing your dataset, \n",
      "eg. \"C://Users/Username/Desktop/Data/:\" on local machine, or \"/content/gdrive/My Drive/Project/Data\" on Google Colab.\n",
      "C://Users/ewand/Downloads\n",
      "Please enter the name of your data file (csv), \n",
      "eg. \"data.csv\":\n",
      "AlShabaabEvents.csv\n",
      "To speed up computation for large datasets\n",
      "multiprocessing can be utilised. Should this be done? (y/n)\n",
      "y\n",
      "How many cores should be used? If left blank half will be used.\n",
      "\n",
      "Does your data contain a country attribute? If so we can filter the AfricaPolis data to speed up processing. (y/n)\n",
      "y\n",
      "\n",
      "Suggested Valid Countries: \n",
      "\n",
      "\n",
      "[1]  democratic republic of the congo\n",
      "[2]  republic of the congo\n",
      "[3]  central african republic\n",
      "[4]  equatorial guinea\n",
      "[5]  cameroon\n",
      "\n",
      "democratic republic of congo does not appear in the AfricaPolis dataset. Please input the index corresponding to the correct country. If the correct country is not available press any other key.\n",
      "\n",
      "democratic republic of congo\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'democratic republic of congo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a0e2de95969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0miso_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcountries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0miso_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miso_lookup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck_valid_country\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miso_lookup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0a0e2de95969>\u001b[0m in \u001b[0;36mcheck_valid_country\u001b[1;34m(string, valid_list)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'[{i}]  {valid_list_sorted[i-1]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mvalid_string_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\n{string} does not appear in the AfricaPolis dataset. Please input the index corresponding to the correct country. If the correct country is not available press any other key.\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mvalid_string_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_string_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_string_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mvalid_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_list_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'democratic republic of congo'"
     ]
    }
   ],
   "source": [
    "class SpinnerThread(threading.Thread):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(target=self._spin)\n",
    "        self._stopevent = threading.Event()\n",
    "\n",
    "    def stop(self):\n",
    "        self._stopevent.set()\n",
    "\n",
    "    def _spin(self):\n",
    "\n",
    "        while not self._stopevent.isSet():\n",
    "            for t in '|/-\\\\':\n",
    "                sys.stdout.write(t)\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(0.5)\n",
    "                sys.stdout.write('\\b')\n",
    "\n",
    "\n",
    "def containment_tests(data, shapes, long_name='longitude', lat_name='latitude'):\n",
    "    spinner_thread = SpinnerThread()\n",
    "    spinner_thread.start()\n",
    "    data = pd.DataFrame(data)\n",
    "    points = gpd.GeoDataFrame(data.loc[:,[long_name,lat_name]], geometry=gpd.points_from_xy(data.loc[:,long_name], data.loc[:,lat_name])) #create a series of point objects representing location of events\n",
    "    polys = shapes.geometry #This is a series of polygons\n",
    "    containment_checker = polys.geometry.buffer(0).contains\n",
    "    tqdm.tqdm.pandas(position=0, leave=True)\n",
    "    spinner_thread.stop()\n",
    "    r = points.geometry.progress_apply(containment_checker)\n",
    "    return r.any(axis=1)\n",
    "\n",
    "def multi_process_containment_tests(data, shapes, long_name='longitude', lat_name='latitude', cores=int(np.round(multiprocessing.cpu_count()/2))):\n",
    "    spinner_thread = SpinnerThread()\n",
    "    spinner_thread.start()\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    points = gpd.GeoDataFrame(data.loc[:,[long_name,lat_name]], geometry=gpd.points_from_xy(data.loc[:,long_name], data.loc[:,lat_name])) #create a series of point objects representing location of events\n",
    "    polys = shapes.geometry #This is a series of polygons\n",
    "    containment_checker = polys.geometry.buffer(0).contains\n",
    "    spinner_thread.stop()\n",
    "    with ProgressBar():  \n",
    "        r = dd.from_pandas(points.geometry, npartitions=cores).map_partitions(lambda dframe: pd.Series(np.any(dframe.apply(containment_checker), axis=1)), meta=pd.Series(dtype=bool)).compute(scheduler='processes')  \n",
    "    return r\n",
    "\n",
    "def yes_no(question):\n",
    "    yes = set(['yes','y'])\n",
    "    no = set(['no','n'])\n",
    "\n",
    "    while True:\n",
    "        choice = input(question).lower()\n",
    "        if choice in yes:\n",
    "            return True\n",
    "        elif choice in no:\n",
    "            return False\n",
    "        else:\n",
    "            print('Please respond with y/n.')\n",
    "        \n",
    "def get_directory(question, error_message, prev_path=''):\n",
    "    dir_ = input(question)\n",
    "    dir_ = os.path.join(prev_path, dir_)\n",
    "    if os.path.exists(dir_):\n",
    "        return dir_\n",
    "    else:\n",
    "        print(error_message)\n",
    "        dir_ = get_directory(question, error_message)\n",
    "        return dir_\n",
    "    \n",
    "def check_valid_country(string, valid_list):\n",
    "    sim_metrics = [jellyfish.levenshtein_distance(string, valid_country) for valid_country in valid_list]\n",
    "    valid_list_sorted = [x for _, x in sorted(zip(sim_metrics,valid_list), key=lambda pair: pair[0])]\n",
    "    if string not in [_ for _ in valid_list]:\n",
    "        print('\\nSuggested Valid Countries: \\n\\n')\n",
    "        for i in range(1, 6):\n",
    "            print(f'[{i}]  {valid_list_sorted[i-1]}')\n",
    "        valid_string_index = input(f'\\n{string} does not appear in the AfricaPolis dataset. Please input the index corresponding to the correct country. If the correct country is not available press any other key.\\n\\n')\n",
    "        if valid_string_index in [str(x) for x in range(1,6)]:\n",
    "            valid_string = valid_list_sorted[int(valid_string_index)-1]\n",
    "        else:\n",
    "            valid_string = input('Please enter the correct country name: ')\n",
    "            valid_string = check_valid_country(valid_string, valid_list)\n",
    "    else:\n",
    "        valid_string = string\n",
    "    return valid_string\n",
    "             \n",
    "\n",
    "if __name__ == '__main__':\n",
    "            \n",
    "    data_dir = get_directory('Please enter the directory containing your dataset, \\neg. \"C://Users/Username/Desktop/Data/:\" on local machine, or \"/content/gdrive/My Drive/Project/Data\" on Google Colab.\\n',\n",
    "                           \"That path doesn't exist, please enter the correct path.\")\n",
    "\n",
    "    data_filename = get_directory('Please enter the name of your data file (csv), \\neg. \"data.csv\":\\n',\n",
    "                               \"The file you have given does not exist in the specified directory. Please check the details given and start again if necessary.\",\n",
    "                               data_dir)\n",
    "    \n",
    "    multiprocess = yes_no('To speed up computation for large datasets\\nmultiprocessing can be utilised. Should this be done? (y/n)\\n')\n",
    "\n",
    "    if multiprocess:\n",
    "        cores = input('How many cores should be used? If left blank half will be used.\\n')\n",
    "        if cores == '':\n",
    "            cores = int(np.round(multiprocessing.cpu_count()/2))\n",
    "        else: cores = int(cores)\n",
    "        \n",
    "    data = pd.read_csv(os.path.join(data_dir, data_filename))\n",
    "    \n",
    "    country_filter = yes_no('Does your data contain a country attribute? If so we can filter the AfricaPolis data to speed up processing. (y/n)\\n')\n",
    "    \n",
    "    if country_filter:\n",
    "        if 'country' not in data.columns:\n",
    "            country_col = input('Please enter the name of the Country column.\\n')\n",
    "        else:\n",
    "            country_col = 'country'\n",
    "            \n",
    "        countries = np.unique(data[country_col])\n",
    "        \n",
    "        countries_url = 'http://www.africapolis.org/download/Africapolis_country.xlsx'\n",
    "        countries_data = pd.read_excel(countries_url, skiprows=15)\n",
    "        iso_lookup = dict(zip([string.lower() for string in countries_data.Country], countries_data.ISO))\n",
    "        \n",
    "        iso_list = list()\n",
    "        for country in countries:\n",
    "            iso_list.append(iso_lookup[check_valid_country(country.lower(), iso_lookup.keys())]) \n",
    "\n",
    "    def load_data():\n",
    "        global africapolis\n",
    "        try: \n",
    "            africapolis = gpd.read_file(os.path.join(data_dir, 'africapolis.shp'))\n",
    "        except Exception:\n",
    "            africapolis_url = 'http://www.africapolis.org/download/Africapolis_2015_shp.zip'\n",
    "            africapolis = gpd.read_file(africapolis_url)\n",
    "        if country_filter:\n",
    "            bools = [iso in iso_list for iso in africapolis.ISO]\n",
    "            africapolis = africapolis[bools]\n",
    "\n",
    "    print('Loading Data ')\n",
    "    task = threading.Thread(target=load_data)\n",
    "    task.start()\n",
    "\n",
    "    spinner_thread = SpinnerThread()\n",
    "    spinner_thread.start()\n",
    "\n",
    "    task.join()\n",
    "    \n",
    "    spinner_thread.stop()\n",
    "\n",
    "    long_name = 'longitude'\n",
    "    lat_name = 'latitude'\n",
    "\n",
    "    def check_col(col_name):\n",
    "        if col_name not in list(data.columns):\n",
    "            col_name = input(f\"Dataset doesn't contain column named {col_name}. Please enter the name of longitude column.\\n\")\n",
    "            col_name = check_col(col_name)\n",
    "        return col_name\n",
    "\n",
    "    long_name = check_col('longitude')\n",
    "    lat_name = check_col('latitude')\n",
    "\n",
    "    print('\\bStarting processing...\\n')\n",
    "    if multiprocess:\n",
    "        print('The progress bar updates as the tasks are completed, may stay on 0% for a long time.')\n",
    "        isurban = multi_process_containment_tests(data=data, \n",
    "                                                  shapes=africapolis,\n",
    "                                                  long_name=long_name,\n",
    "                                                  lat_name=lat_name,\n",
    "                                                  cores=cores)\n",
    "    else:\n",
    "        isurban = containment_tests(data=data, \n",
    "                                    shapes=africapolis,\n",
    "                                    long_name=long_name,\n",
    "                                    lat_name=lat_name)\n",
    "\n",
    "    data['is_urban'] = isurban\n",
    "    print('Saving Data...')\n",
    "    data.to_csv(os.path.join(data_dir, 'processed_data.csv'))\n",
    "\n",
    "    print('Done!')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "indentUnit": 2
   }
  },
  "colab": {
   "name": "urban-africa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
